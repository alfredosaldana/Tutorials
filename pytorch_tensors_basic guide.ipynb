{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "title",
      "metadata": {},
      "source": [
        "# Complete Guide to Understanding PyTorch Tensors\n\n## From Fundamentals to Advanced Operations\n\n**Enhanced and extended tutorial on PyTorch tensors with extensive explanations, visualizations, and practical examples.**\n\n---\n\n### \ud83d\udcda Table of Contents\n1. [Introduction and Setup](#intro)\n2. [What Are Tensors?](#what)\n3. [Core Concepts: Rank, Axes, and Shape](#core)\n4. [Creating Tensors](#create)\n5. [Tensor Properties](#properties)\n6. [Indexing and Slicing](#indexing)\n7. [Reshaping Operations](#reshape)\n8. [Broadcasting](#broadcast)\n9. [Tensor Operations](#ops)\n10. [Concatenation and Stacking](#concat)\n11. [Reduction Operations](#reduce)\n12. [Practical Examples](#practical)\n13. [Summary and Best Practices](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "---\n\n## 1. Introduction and Setup <a id='intro'></a>\n\nLet's start by importing the necessary libraries and setting up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Display PyTorch version and CUDA availability\nprint(f\"PyTorch Version: {torch.__version__}\")\nprint(f\"CUDA Available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n\nprint(\"\\n\u2705 Setup complete! Let's begin learning about tensors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "what",
      "metadata": {},
      "source": [
        "---\n\n## 2. What Are Tensors? <a id='what'></a>\n\n### Definition\n\nA **tensor** is a mathematical object that generalizes scalars, vectors, and matrices to higher dimensions. In deep learning, tensors are the fundamental data structure:\n\n- **Scalar** (0D tensor): A single number (e.g., `5`)\n- **Vector** (1D tensor): An array of numbers (e.g., `[1, 2, 3]`)\n- **Matrix** (2D tensor): A 2D array (e.g., a table/spreadsheet)\n- **3D Tensor**: Three-dimensional array (e.g., RGB image with color channels)\n- **4D+ Tensor**: Higher-dimensional data (e.g., batch of images, video data)\n\n### Why Tensors Matter\n\n1. **Universal Data Representation**: All data (images, text, audio) can be represented as tensors\n2. **GPU Acceleration**: Tensors can be moved to GPUs for fast parallel computation\n3. **Automatic Differentiation**: PyTorch tensors support automatic gradient computation\n4. **Efficient Operations**: Optimized for mathematical operations on large datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "viz_dims",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize different tensor dimensions\nprint(\"=\"*70)\nprint(\"UNDERSTANDING TENSOR DIMENSIONS\")\nprint(\"=\"*70)\n\n# 0D - Scalar\nscalar = torch.tensor(42)\nprint(f\"\\n\ud83d\udccd 0D Tensor (Scalar):\")\nprint(f\"   Value: {scalar}\")\nprint(f\"   Shape: {scalar.shape}  \u2190 Empty tuple means 0D\")\nprint(f\"   Access: Just use .item() to get value: {scalar.item()}\")\n\n# 1D - Vector\nvector = torch.tensor([1, 2, 3, 4, 5])\nprint(f\"\\n\ud83d\udccd 1D Tensor (Vector):\")\nprint(f\"   Value: {vector}\")\nprint(f\"   Shape: {vector.shape}\")\nprint(f\"   Access element: vector[2] = {vector[2]}\")\n\n# 2D - Matrix\nmatrix = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(f\"\\n\ud83d\udccd 2D Tensor (Matrix):\")\nprint(f\"   Value:\\n{matrix}\")\nprint(f\"   Shape: {matrix.shape}  \u2190 (rows, columns)\")\nprint(f\"   Access element: matrix[1, 2] = {matrix[1, 2]}\")\n\n# 3D - Tensor\ntensor_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\nprint(f\"\\n\ud83d\udccd 3D Tensor:\")\nprint(f\"   Value:\\n{tensor_3d}\")\nprint(f\"   Shape: {tensor_3d.shape}  \u2190 (depth, rows, columns)\")\nprint(f\"   Access element: tensor_3d[1, 0, 1] = {tensor_3d[1, 0, 1]}\")\n\nprint(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "core",
      "metadata": {},
      "source": [
        "---\n\n## 3. Core Concepts: Rank, Axes, and Shape <a id='core'></a>\n\nThese three concepts are fundamental to understanding tensors.\n\n### \ud83c\udfaf Rank (Number of Dimensions)\n\n**Definition**: The rank is the number of indices needed to access a single element.\n\n- **Rank 0**: Scalar - no indices needed\n- **Rank 1**: Vector - 1 index (e.g., `array[2]`)\n- **Rank 2**: Matrix - 2 indices (e.g., `matrix[1, 2]`)\n- **Rank 3**: 3D Tensor - 3 indices (e.g., `tensor[0, 1, 2]`)\n\n### \ud83d\udccf Axes (Dimensions)\n\n**Definition**: Each axis is a specific dimension of the tensor.\n\n- The number of axes equals the rank\n- Each axis has a length (number of elements along that axis)\n- Elements \"run along\" each axis\n- **Important**: In a tensor, the **last axis always contains scalar numbers**; all other axes contain nested arrays\n\n### \ud83d\udcd0 Shape\n\n**Definition**: The shape is a tuple showing the length of each axis.\n\n- Shape completely describes the tensor's structure\n- **Total elements** = product of all dimensions in shape\n- Example: Shape `(2, 3, 4)` means 2 \u00d7 3 \u00d7 4 = 24 elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rank_examples",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive examples of Rank, Axes, and Shape\nprint(\"=\"*70)\nprint(\"RANK, AXES, AND SHAPE EXPLAINED\")\nprint(\"=\"*70)\n\n# Example with different shapes\nexamples = [\n    (\"Scalar\", torch.tensor(7)),\n    (\"Vector\", torch.tensor([1, 2, 3, 4])),\n    (\"Matrix\", torch.arange(12).reshape(3, 4)),\n    (\"3D Tensor\", torch.arange(24).reshape(2, 3, 4)),\n    (\"4D Tensor\", torch.arange(48).reshape(2, 3, 4, 2)),\n]\n\nfor name, tensor in examples:\n    print(f\"\\n{'\u2500'*70}\")\n    print(f\"{name}:\")\n    print(f\"{'\u2500'*70}\")\n    print(f\"   Shape: {tensor.shape}\")\n    print(f\"   Rank: {len(tensor.shape)} (number of dimensions)\")\n    print(f\"   Total elements: {tensor.numel()}\")\n    \n    if len(tensor.shape) > 0:\n        calculation = \" \u00d7 \".join(str(d) for d in tensor.shape)\n        print(f\"   Calculation: {calculation} = {tensor.numel()}\")\n    \n    # Show how to access elements based on rank\n    if len(tensor.shape) == 0:\n        print(f\"   Access: tensor.item() = {tensor.item()}\")\n    elif len(tensor.shape) == 1:\n        print(f\"   Access: tensor[0] = {tensor[0]}\")\n    elif len(tensor.shape) == 2:\n        print(f\"   Access: tensor[0, 0] = {tensor[0, 0]}\")\n    elif len(tensor.shape) == 3:\n        print(f\"   Access: tensor[0, 0, 0] = {tensor[0, 0, 0]}\")\n    else:\n        print(f\"   Access: tensor[0, 0, 0, 0] = {tensor[0, 0, 0, 0]}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"KEY INSIGHT: Rank = Number of square brackets = Number of indices needed\")\nprint(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "axes_detail",
      "metadata": {},
      "source": [
        "### Understanding Axes in Detail\n\nLet's explore how axes work with a practical example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "axes_deep",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deep dive into axes\nprint(\"=\"*70)\nprint(\"UNDERSTANDING AXES (DIMENSIONS)\")\nprint(\"=\"*70)\n\n# Create a 3x4 matrix\nmatrix = torch.arange(1, 13).reshape(3, 4)\nprint(f\"\\n Matrix (3 rows \u00d7 4 columns):\\n{matrix}\")\n\nprint(f\"\\n\ud83d\udd0d This tensor has 2 axes:\")\nprint(f\"   \u2022 Axis 0 (rows): length = {matrix.shape[0]}\")\nprint(f\"   \u2022 Axis 1 (columns): length = {matrix.shape[1]}\")\n\nprint(f\"\\n\ud83d\udccd Accessing along Axis 0 (selecting entire rows):\")\nfor i in range(3):\n    print(f\"   matrix[{i}] = {matrix[i]}\")\n\nprint(f\"\\n\ud83d\udccd Accessing along Axis 1 (selecting entire columns):\")\nfor j in range(4):\n    print(f\"   matrix[:, {j}] = {matrix[:, j]}\")\n\nprint(f\"\\n\ud83d\udccd Accessing specific elements (using both axes):\")\nprint(f\"   matrix[1, 2] = {matrix[1, 2]}  \u2190 Row 1, Column 2\")\nprint(f\"   matrix[0, 3] = {matrix[0, 3]}  \u2190 Row 0, Column 3\")\nprint(f\"   matrix[2, 1] = {matrix[2, 1]}  \u2190 Row 2, Column 1\")\n\nprint(\"\\n\" + \"=\"*70)\n\n# 3D Example\nprint(\"\\n3D TENSOR AXES EXAMPLE\")\nprint(\"=\"*70)\n\ntensor_3d = torch.arange(1, 25).reshape(2, 3, 4)\nprint(f\"\\nTensor shape: {tensor_3d.shape}  (2 layers, 3 rows, 4 columns)\")\n\nprint(f\"\\n\ud83d\udd0d This tensor has 3 axes:\")\nprint(f\"   \u2022 Axis 0 (layers/depth): length = {tensor_3d.shape[0]}\")\nprint(f\"   \u2022 Axis 1 (rows/height): length = {tensor_3d.shape[1]}\")\nprint(f\"   \u2022 Axis 2 (columns/width): length = {tensor_3d.shape[2]}\")\n\nprint(f\"\\nLayer 0:\\n{tensor_3d[0]}\")\nprint(f\"\\nLayer 1:\\n{tensor_3d[1]}\")\n\nprint(f\"\\n\ud83d\udccd Different ways to access:\")\nprint(f\"   tensor_3d[0] gives entire first layer (2D):\\n{tensor_3d[0]}\")\nprint(f\"\\n   tensor_3d[1, 2] gives row 2 of layer 1 (1D): {tensor_3d[1, 2]}\")\nprint(f\"\\n   tensor_3d[0, 1, 2] gives specific element: {tensor_3d[0, 1, 2]}\")\n\nprint(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "shape_viz",
      "metadata": {},
      "source": [
        "### Visualizing Shape Transformations\n\nThe same data can be arranged in different shapes as long as the total number of elements remains constant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "shape_transform",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Shape transformation examples\nprint(\"=\"*70)\nprint(\"SHAPE TRANSFORMATIONS (Same 12 Elements, Different Shapes)\")\nprint(\"=\"*70)\n\nbase_data = list(range(1, 13))  # 12 elements\nprint(f\"\\nBase data: {base_data}\\n\")\n\nshapes = [\n    ((12,), \"1D Vector\"),\n    ((3, 4), \"3\u00d74 Matrix\"),\n    ((4, 3), \"4\u00d73 Matrix\"),\n    ((2, 6), \"2\u00d76 Matrix\"),\n    ((6, 2), \"6\u00d72 Matrix\"),\n    ((2, 2, 3), \"2\u00d72\u00d73 3D Tensor\"),\n    ((1, 12), \"1\u00d712 Row Matrix\"),\n    ((12, 1), \"12\u00d71 Column Matrix\"),\n]\n\nfor shape, description in shapes:\n    try:\n        t = torch.tensor(base_data).reshape(shape)\n        print(f\" Shape {str(shape):15} \u2192 {description:20} \u2713\")\n    except:\n        print(f\"Shape {str(shape):15} \u2192 {description:20} \u2717 (Invalid)\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"\ud83d\udca1 KEY RULE: Total elements must remain constant!\")\nprint(f\"   All valid shapes multiply to {len(base_data)} elements\")\nprint(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "create_intro",
      "metadata": {},
      "source": [
        "---\n\n## 4. Creating Tensors in PyTorch <a id='create'></a>\n\nPyTorch provides many ways to create tensors. Let's explore the most common methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "create_from_data",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"CREATING TENSORS - FROM DATA\")\nprint(\"=\"*70)\n\n# From Python list\nprint(\"\\n1\ufe0f\u20e3 From Python List:\")\ndata = [[1, 2, 3], [4, 5, 6]]\nt_from_list = torch.tensor(data)\nprint(f\"   List: {data}\")\nprint(f\"   Tensor:\\n{t_from_list}\")\nprint(f\"   Shape: {t_from_list.shape}, dtype: {t_from_list.dtype}\")\n\n# From NumPy array\nprint(\"\\n2\ufe0f\u20e3 From NumPy Array:\")\nnp_array = np.array([[1.0, 2.0], [3.0, 4.0]])\nt_from_numpy = torch.from_numpy(np_array)\nprint(f\"   NumPy array:\\n{np_array}\")\nprint(f\"   Tensor:\\n{t_from_numpy}\")\nprint(f\"   Shape: {t_from_numpy.shape}, dtype: {t_from_numpy.dtype}\")\n\n# Specifying data types\nprint(\"\\n3\ufe0f\u20e3 Specifying Data Types:\")\nt_int = torch.tensor([1, 2, 3], dtype=torch.int32)\nt_float = torch.tensor([1, 2, 3], dtype=torch.float32)\nt_double = torch.tensor([1, 2, 3], dtype=torch.float64)\nprint(f\"   int32:   {t_int} | dtype: {t_int.dtype}\")\nprint(f\"   float32: {t_float} | dtype: {t_float.dtype}\")\nprint(f\"   float64: {t_double} | dtype: {t_double.dtype}\")\n\nprint(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "create_special",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"CREATING TENSORS - SPECIAL VALUES\")\nprint(\"=\"*70)\n\n# Zeros\nprint(\"\\n1\ufe0f\u20e3 Zeros:\")\nzeros = torch.zeros(2, 3)\nprint(f\"{zeros}\")\n\n# Ones\nprint(\"\\n2\ufe0f\u20e3 Ones:\")\nones = torch.ones(2, 3)\nprint(f\"{ones}\")\n\n# Identity matrix\nprint(\"\\n3\ufe0f\u20e3 Identity Matrix:\")\nidentity = torch.eye(3)\nprint(f\"{identity}\")\n\n# Full (specific value)\nprint(\"\\n4\ufe0f\u20e3 Filled with Specific Value:\")\nfilled = torch.full((2, 3), 7.5)\nprint(f\"{filled}\")\n\n# Random values\nprint(\"\\n5\ufe0f\u20e3 Random Values:\")\nrand_uniform = torch.rand(2, 3)  # Uniform [0, 1)\nrand_normal = torch.randn(2, 3)  # Normal distribution\nrand_int = torch.randint(0, 10, (2, 3))  # Random integers\nprint(f\"   Uniform [0,1):\\n{rand_uniform}\")\nprint(f\"\\n   Normal (\u03bc=0, \u03c3=1):\\n{rand_normal}\")\nprint(f\"\\n   Random ints [0,10):\\n{rand_int}\")\n\n# Ranges\nprint(\"\\n6\ufe0f\u20e3 Ranges:\")\narange = torch.arange(0, 10, 2)\nlinspace = torch.linspace(0, 1, 5)\nprint(f\"   arange(0, 10, 2): {arange}\")\nprint(f\"   linspace(0, 1, 5): {linspace}\")\n\nprint(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "props_intro",
      "metadata": {},
      "source": [
        "---\n\n## 5. Tensor Properties and Attributes <a id='properties'></a>\n\nUnderstanding tensor attributes helps you debug and manipulate tensors correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "props_show",
      "metadata": {},
      "outputs": [],
      "source": [
        "t = torch.randn(2, 3, 4)\n\nprint(\"=\"*70)\nprint(\"TENSOR PROPERTIES\")\nprint(\"=\"*70)\nprint(f\"\\nTensor:\\n{t}\\n\")\nprint(f\"\u2713 Shape: {t.shape}\")\nprint(f\"\u2713 Rank (ndim): {t.ndim}\")\nprint(f\"\u2713 Total elements (numel): {t.numel()}\")\nprint(f\"\u2713 Data type (dtype): {t.dtype}\")\nprint(f\"\u2713 Device: {t.device}\")\nprint(f\"\u2713 Requires grad: {t.requires_grad}\")\nprint(f\"\u2713 Is contiguous: {t.is_contiguous()}\")\nprint(f\"\u2713 Element size: {t.element_size()} bytes\")\nprint(f\"\u2713 Total memory: {t.numel() * t.element_size()} bytes\")\nprint(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "index_intro",
      "metadata": {},
      "source": [
        "---\n\n## 6. Indexing and Slicing <a id='indexing'></a>\n\nIndexing allows you to access and modify specific parts of tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "indexing_examples",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"INDEXING AND SLICING\")\nprint(\"=\"*70)\n\n# 1D\nvec = torch.arange(10)\nprint(f\"\\n1D Tensor: {vec}\")\nprint(f\"   vec[3] = {vec[3]}\")\nprint(f\"   vec[2:5] = {vec[2:5]}\")\nprint(f\"   vec[::2] = {vec[::2]}  (every 2nd element)\")\nprint(f\"   vec[::-1] = {vec[::-1]}  (reversed)\")\n\n# 2D\nmat = torch.arange(12).reshape(3, 4)\nprint(f\"\\n2D Tensor:\\n{mat}\")\nprint(f\"   mat[1, 2] = {mat[1, 2]}\")\nprint(f\"   mat[0] = {mat[0]}  (first row)\")\nprint(f\"   mat[:, 2] = {mat[:, 2]}  (3rd column)\")\nprint(f\"   mat[0:2, 1:3] =\\n{mat[0:2, 1:3]}  (submatrix)\")\n\n# Boolean indexing\nprint(f\"\\nBoolean Indexing:\")\nmask = vec > 5\nprint(f\"   vec > 5: {mask}\")\nprint(f\"   vec[vec > 5] = {vec[mask]}\")\n\nprint(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "reshape_intro",
      "metadata": {},
      "source": [
        "---\n\n## 7. Reshaping Operations <a id='reshape'></a>\n\nReshaping is crucial for preparing data for different neural network layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reshape_ops",
      "metadata": {},
      "outputs": [],
      "source": [
        "base = torch.arange(1, 13, dtype=torch.float32)\n\nprint(\"=\"*70)\nprint(\"RESHAPING OPERATIONS\")\nprint(\"=\"*70)\nprint(f\"\\nBase tensor (12 elements): {base}\\n\")\n\n# Reshape\nprint(\"1\ufe0f\u20e3 RESHAPE - Change shape:\")\nprint(f\"   reshape(3, 4):\\n{base.reshape(3, 4)}\")\nprint(f\"   reshape(2, 2, 3):\\n{base.reshape(2, 2, 3)}\")\nprint(f\"   reshape(3, -1): shape = {base.reshape(3, -1).shape}  (-1 auto-calculates)\")\n\n# Squeeze/Unsqueeze\nprint(f\"\\n2\ufe0f\u20e3 SQUEEZE/UNSQUEEZE - Add/remove size-1 dims:\")\nt = torch.randn(1, 3, 1, 4)\nprint(f\"   Original: {t.shape}\")\nprint(f\"   squeeze(): {t.squeeze().shape}  (removes all size-1)\")\nprint(f\"   squeeze(0): {t.squeeze(0).shape}  (removes dim 0 if size-1)\")\nprint(f\"   unsqueeze(0): {t.squeeze().unsqueeze(0).shape}  (adds size-1 at pos 0)\")\n\n# Flatten\nprint(f\"\\n3\ufe0f\u20e3 FLATTEN - Convert to 1D:\")\nt_2d = base.reshape(3, 4)\nprint(f\"   Original shape: {t_2d.shape}\")\nprint(f\"   Flattened: {t_2d.flatten().shape}\")\n\n# Transpose\nprint(f\"\\n4\ufe0f\u20e3 TRANSPOSE - Swap dimensions:\")\nprint(f\"   Original (3\u00d74):\\n{t_2d}\")\nprint(f\"   Transposed (4\u00d73):\\n{t_2d.t()}\")\n\nprint(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "flatten_custom",
      "metadata": {},
      "source": [
        "### Custom Flatten Function\n\nLet's implement a flatten function as in your original notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "flatten_func",
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten(t):\n    \"\"\"Flatten tensor to 1D.\n    \n    Steps:\n    1. Reshape to (1, -1) - one row, auto columns\n    2. Squeeze to remove size-1 dimension\n    \"\"\"\n    t = t.reshape(1, -1)\n    t = t.squeeze()\n    return t\n\n# Test it\ntest_tensors = [\n    torch.arange(12).reshape(3, 4),\n    torch.arange(12).reshape(2, 2, 3),\n]\n\nprint(\"Testing custom flatten function:\")\nprint(\"=\"*70)\nfor i, t in enumerate(test_tensors, 1):\n    flat = flatten(t)\n    print(f\"\\nTest {i}:\")\n    print(f\"   Original shape: {t.shape}\")\n    print(f\"   Flattened shape: {flat.shape}\")\n    print(f\"   Flattened: {flat}\")\nprint(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broadcast_intro",
      "metadata": {},
      "source": [
        "---\n\n## 8. Broadcasting <a id='broadcast'></a>\n\nBroadcasting allows operations on tensors of different shapes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "broadcast_examples",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"BROADCASTING MECHANICS\")\nprint(\"=\"*70)\n\nprint(\"\\n\ud83d\udcda Broadcasting Rules:\")\nprint(\"   1. Compare shapes from RIGHT to LEFT\")\nprint(\"   2. Dimensions are compatible if:\")\nprint(\"      \u2022 They're equal, OR\")\nprint(\"      \u2022 One of them is 1\")\nprint(\"   3. Shorter shape padded with 1s on LEFT\")\n\n# Example 1: Scalar\nprint(\"\\n\" + \"\u2500\"*70)\nprint(\"Example 1: Scalar Broadcasting\")\nprint(\"\u2500\"*70)\nmat = torch.tensor([[1, 2], [3, 4]])\nscalar = 10\nresult = mat + scalar\nprint(f\"Matrix (2\u00d72):\\n{mat}\")\nprint(f\"Scalar: {scalar}\")\nprint(f\"Result (mat + scalar):\\n{result}\")\n\n# Example 2: Vector to matrix\nprint(\"\\n\" + \"\u2500\"*70)\nprint(\"Example 2: Vector Broadcasting\")\nprint(\"\u2500\"*70)\nmat = torch.tensor([[1, 2, 3], [4, 5, 6]])\nvec = torch.tensor([10, 20, 30])\nresult = mat + vec\nprint(f\"Matrix (2\u00d73):\\n{mat}\")\nprint(f\"Vector (3,): {vec}\")\nprint(f\"Result:\\n{result}\")\nprint(f\"Vector broadcast to each row!\")\n\n# Example 3: Column vector\nprint(\"\\n\" + \"\u2500\"*70)\nprint(\"Example 3: Column Vector Broadcasting\")\nprint(\"\u2500\"*70)\nmat = torch.tensor([[1, 2, 3], [4, 5, 6]])\ncol = torch.tensor([[10], [20]])\nresult = mat + col\nprint(f\"Matrix (2\u00d73):\\n{mat}\")\nprint(f\"Column (2\u00d71):\\n{col}\")\nprint(f\"Result:\\n{result}\")\nprint(f\"Column broadcast to each column!\")\n\nprint(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "concat_intro",
      "metadata": {},
      "source": [
        "---\n\n## 9. Concatenation and Stacking <a id='concat'></a>\n\nCombining tensors is common when building batches or merging features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "concat_stack",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"CONCATENATION vs STACKING\")\nprint(\"=\"*70)\n\n# Concatenation\nprint(\"\\n1\ufe0f\u20e3 CONCATENATION (torch.cat) - Join along EXISTING dimension\")\nprint(\"\u2500\"*70)\n\nt1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\nt2 = torch.tensor([[7, 8, 9], [10, 11, 12]])\n\nprint(f\"\\nt1 (2\u00d73):\\n{t1}\")\nprint(f\"\\nt2 (2\u00d73):\\n{t2}\")\n\ncat_dim0 = torch.cat([t1, t2], dim=0)\ncat_dim1 = torch.cat([t1, t2], dim=1)\n\nprint(f\"\\ncat(dim=0) - Concatenate rows:\")\nprint(f\"   Shape: {cat_dim0.shape}  (4\u00d73)\")\nprint(f\"{cat_dim0}\")\n\nprint(f\"\\ncat(dim=1) - Concatenate columns:\")\nprint(f\"   Shape: {cat_dim1.shape}  (2\u00d76)\")\nprint(f\"{cat_dim1}\")\n\n# Stacking\nprint(\"\\n\\n2\ufe0f\u20e3 STACKING (torch.stack) - Create NEW dimension\")\nprint(\"\u2500\"*70)\n\nt1 = torch.tensor([1, 2, 3])\nt2 = torch.tensor([4, 5, 6])\n\nprint(f\"\\nt1 (3,): {t1}\")\nprint(f\"t2 (3,): {t2}\")\n\nstack_dim0 = torch.stack([t1, t2], dim=0)\nstack_dim1 = torch.stack([t1, t2], dim=1)\n\nprint(f\"\\nstack(dim=0):\")\nprint(f\"   Shape: {stack_dim0.shape}  (2\u00d73) - NEW dimension created\")\nprint(f\"{stack_dim0}\")\n\nprint(f\"\\nstack(dim=1):\")\nprint(f\"   Shape: {stack_dim1.shape}  (3\u00d72)\")\nprint(f\"{stack_dim1}\")\n\nprint(\"\\n\ud83d\udca1 Key Difference:\")\nprint(\"   \u2022 cat:   Extends existing dimension\")\nprint(\"   \u2022 stack: Creates new dimension (increases rank by 1)\")\n\nprint(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ops_intro",
      "metadata": {},
      "source": [
        "---\n\n## 10. Tensor Operations <a id='ops'></a>\n\nPyTorch provides many operations for manipulating tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tensor_ops",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"TENSOR OPERATIONS\")\nprint(\"=\"*70)\n\na = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\nb = torch.tensor([[5.0, 6.0], [7.0, 8.0]])\n\nprint(f\"\\na =\\n{a}\")\nprint(f\"\\nb =\\n{b}\")\n\nprint(\"\\n1\ufe0f\u20e3 ARITHMETIC:\")\nprint(f\"   a + b =\\n{a + b}\")\nprint(f\"   a * b (element-wise) =\\n{a * b}\")\nprint(f\"   a @ b (matrix mult) =\\n{a @ b}\")\nprint(f\"   a ** 2 =\\n{a ** 2}\")\n\nprint(\"\\n2\ufe0f\u20e3 MATHEMATICAL FUNCTIONS:\")\nx = torch.tensor([1.0, 2.0, 3.0, 4.0])\nprint(f\"   x = {x}\")\nprint(f\"   sqrt(x) = {torch.sqrt(x)}\")\nprint(f\"   exp(x) = {torch.exp(x)}\")\nprint(f\"   log(x) = {torch.log(x)}\")\n\nprint(\"\\n3\ufe0f\u20e3 COMPARISON:\")\nprint(f\"   a > 2 =\\n{a > 2}\")\nprint(f\"   a == b =\\n{a == b}\")\n\nprint(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "reduce_intro",
      "metadata": {},
      "source": [
        "---\n\n## 11. Reduction Operations <a id='reduce'></a>\n\nReductions aggregate values across dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reductions",
      "metadata": {},
      "outputs": [],
      "source": [
        "t = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n\nprint(\"=\"*70)\nprint(\"REDUCTION OPERATIONS\")\nprint(\"=\"*70)\nprint(f\"\\nTensor (3\u00d73):\\n{t}\\n\")\n\nprint(\"\ud83d\udcca Reduce ALL elements:\")\nprint(f\"   sum: {t.sum()}\")\nprint(f\"   mean: {t.mean()}\")\nprint(f\"   max: {t.max()}\")\nprint(f\"   min: {t.min()}\")\nprint(f\"   std: {t.std()}\")\n\nprint(\"\\n\ud83d\udcca Reduce along dimension:\")\nprint(f\"   sum(dim=0) - sum columns: {t.sum(dim=0)}\")\nprint(f\"   sum(dim=1) - sum rows: {t.sum(dim=1)}\")\nprint(f\"   mean(dim=0): {t.mean(dim=0)}\")\nprint(f\"   max(dim=1): {t.max(dim=1)}  \u2192 (values, indices)\")\n\nprint(\"\\n\ud83d\udcca With keepdim:\")\nsum_keepdim = t.sum(dim=0, keepdim=True)\nprint(f\"   sum(dim=0, keepdim=True): shape={sum_keepdim.shape}\")\nprint(f\"   {sum_keepdim}\")\n\nprint(\"\\n\ud83d\udca1 keepdim=True preserves dimensions for broadcasting!\")\nprint(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "practical_intro",
      "metadata": {},
      "source": [
        "---\n\n## 12. Practical Examples <a id='practical'></a>\n\nLet's apply these concepts to real scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "practical1",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"PRACTICAL EXAMPLE: Image Batch Processing\")\nprint(\"=\"*70)\n\n# Simulate batch of images (batch, channels, height, width)\nbatch_size = 32\nchannels = 3  # RGB\nheight, width = 224, 224\n\nimages = torch.randn(batch_size, channels, height, width)\n\nprint(f\"\\n\ud83d\udcf8 Image batch: {images.shape}\")\nprint(f\"   Interpretation: (batch={batch_size}, channels={channels}, h={height}, w={width})\")\n\n# Normalize per channel\nmean = images.mean(dim=[0, 2, 3], keepdim=True)\nstd = images.std(dim=[0, 2, 3], keepdim=True)\nnormalized = (images - mean) / std\n\nprint(f\"\\n\u2728 Normalization:\")\nprint(f\"   Mean shape: {mean.shape}  (per channel)\")\nprint(f\"   Normalized shape: {normalized.shape}\")\nprint(f\"   Check: mean \u2248 {normalized.mean():.6f}, std \u2248 {normalized.std():.6f}\")\n\n# Flatten for fully connected layer\nflattened = images.view(batch_size, -1)\nprint(f\"\\n\ud83d\udd04 Flattening for FC layer:\")\nprint(f\"   Flattened shape: {flattened.shape}\")\nprint(f\"   (batch={batch_size}, features={channels*height*width})\")\n\nprint(\"\\n\ud83d\udca1 All operations efficiently handle the entire batch!\")\nprint(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary",
      "metadata": {},
      "source": [
        "---\n\n## 13. Summary and Best Practices <a id='summary'></a>\n\n### \ud83c\udfaf Key Concepts Recap\n\n1. **Tensors** are multi-dimensional arrays that generalize scalars, vectors, and matrices\n2. **Rank** = number of indices needed to access an element\n3. **Shape** = tuple of dimension lengths\n4. **Axes** = individual dimensions of the tensor\n5. **Broadcasting** allows operations on different shaped tensors\n\n### \u2705 Best Practices\n\n1. **Always check shapes** - Most errors come from shape mismatches\n2. **Use broadcasting** - More efficient than loops\n3. **Choose right dtype** - float32 for most deep learning\n4. **Mind the device** - Keep tensors on same device (CPU/GPU)\n5. **Batch operations** - Process multiple samples together\n6. **Use `.contiguous()`** when needed for performance\n7. **Leverage `.view()` vs `.reshape()`** - understand the difference\n8. **Use `torch.no_grad()`** during inference\n\n### \ud83d\udcda Common Patterns\n\n```python\n# Add batch dimension\ntensor = tensor.unsqueeze(0)\n\n# Remove batch dimension  \ntensor = tensor.squeeze(0)\n\n# Flatten for FC layer\nflat = tensor.view(batch_size, -1)\n\n# Normalize data\nnormalized = (data - mean) / std\n\n# Matrix multiplication\nresult = A @ B\n```\n\n### \ud83d\udd17 Resources\n\n- PyTorch Documentation: https://pytorch.org/docs/\n- PyTorch Tutorials: https://pytorch.org/tutorials/\n\n---\n\n### Credits\n\nThis enhanced notebook extends concepts from the deeplizard tutorial series.\n\nOriginal: https://www.youtube.com/watch?v=Csa5R12jYRg\n\n---\n\n**Happy Learning! \ud83d\ude80**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}